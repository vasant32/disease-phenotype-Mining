This paper examines the feasibility of the trend covariability between QT and RR Intervals (QTIs and RRIs) be a novel mean of the sudden cardiac death (SCD) risk stratification. Twenty four hour beat to beat QTIs and RRIs are measured from Holter ECG recordings of 25 normal control subjects (SCD-C), 14 low SCD risk patients (SCD-L) with high blood pressure or light cardiac arrhythmia and 11 SCD high risk patients (SCD-H) with heart attack history. The Kalman filtering technique has been applied to decompose 24 hour short term mean QTIs and RRIs sequences into trend components and additive random variations. The correlation coefficients (TC-QT/RR) and cross entropies (TE-QT/RR) between the QT and RR trend signals are estimated. Cross entropy TE-QT/RR achieved the best stratification of subject groups. TE-QT/RR distribution for SCD-C, -L -H subject groups were 1.697 ± 0.058, 1.160 ± 0.099, 0.920 ± 0.067. The differences in entropy values are statistically significant for all classes pairs (SCD-H and -C (p<0.00001); -L and -C (p<0.001); -H and -L (p<0.05) The result indicates that the TE-QT/RR could be a novel index for the SCD risk stratification.